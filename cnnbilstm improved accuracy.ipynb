{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07188c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707aeb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['word', 'food', 'crapilicious']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['white']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['classy', 'whore', 'red', 'velvet', 'cupcake']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['meh', 'p', 'thanks', 'head', 'concerned', 'a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['isi', 'account', 'pretending', 'kurdish', 'a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  label\n",
       "0                   ['word', 'food', 'crapilicious']      0\n",
       "1                                          ['white']      0\n",
       "2    ['classy', 'whore', 'red', 'velvet', 'cupcake']      0\n",
       "3  ['meh', 'p', 'thanks', 'head', 'concerned', 'a...      0\n",
       "4  ['isi', 'account', 'pretending', 'kurdish', 'a...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/localadmin/Desktop/cleaned_multiclass_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf5d6b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    7998\n",
       "2    7992\n",
       "3    7973\n",
       "4    7961\n",
       "0    7945\n",
       "5    7823\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01b69bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df['cleaned_text']\n",
    "y= df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08653619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31520,) (13509,) (31520,) (13509,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3,stratify=y, random_state=42)\n",
    "print(x_train.shape,x_test.shape, y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b63f9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ff2c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2663"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_text\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49d47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(\"cleaned_text\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a095dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    7963\n",
       "2    7905\n",
       "4    7757\n",
       "0    7742\n",
       "3    7721\n",
       "5    5941\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35cadbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 20:53:22.410502: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_x_train shape: (31520, 5000)\n",
      "np_x_test shape: (13509, 5000)\n",
      "np_y_train shape: (31520, 6)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "max_length = 5000\n",
    "max_features = 20000\n",
    "embedding_dim = 300\n",
    "\n",
    "x_all = []\n",
    "x_all.extend(x_test)\n",
    "x_all.extend(x_train)\n",
    "\n",
    "tk = Tokenizer(num_words=max_features, lower=True, filters='\\n\\t')\n",
    "tk.fit_on_texts(x_all)\n",
    "x_train_seq = tk.texts_to_sequences(x_train)\n",
    "x_test_seq = tk.texts_to_sequences(x_test)\n",
    "\n",
    "np_x_train = pad_sequences(x_train_seq, maxlen=max_length,  padding='post')\n",
    "np_x_test = pad_sequences(x_test_seq, maxlen=max_length,  padding='post')\n",
    "np_y_train = to_categorical(y_train)\n",
    "\n",
    "class_num = np_y_train.shape[1]\n",
    "\n",
    "print ('np_x_train shape: {}'.format(np_x_train.shape))\n",
    "print ('np_x_test shape: {}'.format(np_x_test.shape))\n",
    "print ('np_y_train shape: {}'.format(np_y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284670c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m np_x_train_resampled, np_y_train_resampled \u001b[38;5;241m=\u001b[39m ros\u001b[38;5;241m.\u001b[39mfit_resample(np_x_train_2d, np_y_train\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Reshape back to 3D array\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m np_x_train_resampled \u001b[38;5;241m=\u001b[39m np_x_train_resampled\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, max_length, np_x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Convert labels back to categorical\u001b[39;00m\n\u001b[1;32m     16\u001b[0m np_y_train_resampled \u001b[38;5;241m=\u001b[39m to_categorical(np_y_train_resampled, num_classes\u001b[38;5;241m=\u001b[39mclass_num)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Reshape np_x_train to 2D array\n",
    "np_x_train_2d = np_x_train.reshape((np_x_train.shape[0], -1))\n",
    "\n",
    "# Instantiate RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and apply the oversampler to the training data\n",
    "np_x_train_resampled, np_y_train_resampled = ros.fit_resample(np_x_train_2d, np_y_train.argmax(axis=1))\n",
    "\n",
    "# Reshape back to 3D array\n",
    "np_x_train_resampled = np_x_train_resampled.reshape((-1, max_length, np_x_train.shape[2]))\n",
    "\n",
    "# Convert labels back to categorical\n",
    "np_y_train_resampled = to_categorical(np_y_train_resampled, num_classes=class_num)\n",
    "\n",
    "print ('np_x_train_resampled shape: {}'.format(np_x_train_resampled.shape))\n",
    "print ('np_y_train_resampled shape: {}'.format(np_y_train_resampled.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cc3cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = y_train_resampled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65cf24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_resampled shape: (33444, 5000, 1)\n",
      "y_train_resampled shape: (33444, 6)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Assuming you have x_train, y_train as your original data\n",
    "max_length = 5000\n",
    "max_features = 20000\n",
    "embedding_dim = 300\n",
    "\n",
    "# Combine text data for tokenization\n",
    "x_all = x_train.copy()\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tk = Tokenizer(num_words=max_features, lower=True, filters='\\n\\t')\n",
    "tk.fit_on_texts(x_all)\n",
    "x_train_seq = tk.texts_to_sequences(x_train)\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_pad, y_train_categorical.argmax(axis=1))\n",
    "\n",
    "# Reshape the resampled data back to 3D array\n",
    "x_train_resampled = x_train_resampled.reshape((-1, max_length, 1))  # Assuming 1 as the embedding_dim\n",
    "\n",
    "# Convert labels back to categorical\n",
    "y_train_resampled = to_categorical(y_train_resampled, num_classes=6)\n",
    "\n",
    "# Now you can use x_train_resampled and y_train_resampled in your CNN model\n",
    "print('x_train_resampled shape:', x_train_resampled.shape)\n",
    "print('y_train_resampled shape:', y_train_resampled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd28793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5000)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 5000, 300)         6000000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 4992, 32)          86432     \n",
      "                                                                 \n",
      " maxpool1d_1 (MaxPooling1D)  (None, 312, 32)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 312, 32)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 306, 32)           7200      \n",
      "                                                                 \n",
      " maxpool1d_2 (MaxPooling1D)  (None, 38, 32)            0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 38, 32)            0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 64)                16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " preds (Dense)               (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6110662 (23.31 MB)\n",
      "Trainable params: 6110662 (23.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "732/732 [==============================] - 1580s 2s/step - loss: 0.8630 - accuracy: 0.6437 - val_loss: 0.8472 - val_accuracy: 0.6457\n",
      "Epoch 2/2\n",
      "732/732 [==============================] - 1930s 3s/step - loss: 0.4685 - accuracy: 0.7938 - val_loss: 0.8653 - val_accuracy: 0.6534\n",
      "Epoch 1/2\n",
      "362/732 [=============>................] - ETA: 18:30 - loss: 0.9926 - accuracy: 0.6026"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def one_input_classifier(max_length, max_features, embedding_dim, class_num):\n",
    "    inputs = Input(shape=(max_length,), name='input_1')\n",
    "    embeddings = Embedding(max_features, embedding_dim, input_length=max_length, name='embedding_1')(inputs)\n",
    "\n",
    "    conv_1 = Conv1D(32, 9, activation='relu', name='conv1d_1')(embeddings)\n",
    "    maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
    "    dropout_1 = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
    "\n",
    "    conv_2 = Conv1D(32, 7, activation='relu', name='conv1d_2')(dropout_1)\n",
    "    maxpool_2 = MaxPooling1D(8, name='maxpool1d_2')(conv_2)\n",
    "    dropout_2 = Dropout(0.2, name='dropout_2')(maxpool_2)\n",
    "\n",
    "    bilstm = Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0.2, name='lstm_1'),\n",
    "        name='bidirectional_1')(dropout_2)\n",
    "    preds = Dense(class_num, activation='softmax', name='preds')(bilstm)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "models = []\n",
    "classifier_num = 10\n",
    "\n",
    "for i in range(classifier_num):\n",
    "    model = one_input_classifier(max_length, max_features, embedding_dim, class_num)\n",
    "\n",
    "    if i == 0:\n",
    "        print(model.summary())\n",
    "\n",
    "    model.fit(x_train_resampled, y_train_resampled, validation_split=0.3, shuffle=True, epochs=2, batch_size=32, verbose=1)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9844bb24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming model is the last model in your 'models' list\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m last_model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming x_test and y_test are your test data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m last_model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming model is the last model in your 'models' list\n",
    "last_model = models[-1]\n",
    "\n",
    "# Assuming x_test and y_test are your test data\n",
    "y_pred = last_model.predict(x_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Assuming binary classification\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1af9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
